{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, clone\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "File b'data/tagging/categories.csv' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-3ca7ba8b8d08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/tagging/categories.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.loc[lambda x: x.short_description.str.len() > 10]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    707\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 709\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    710\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1049\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1050\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1693\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1695\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1697\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: File b'data/tagging/categories.csv' does not exist"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/tagging/categories.csv')#.loc[lambda x: x.short_description.str.len() > 10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The task is to predict not one but multiple categories for each observation. \n",
    "One of the solutions is to create a binary classifier for each unique category.\n",
    "It is fairly simple to do using scikit-learn but we need to create our own classifier.\n",
    "\n",
    "Task:\n",
    "\n",
    "1. Write a custom classifier to solve this.\n",
    "2. Evaluate its results (what measure could be good for comparing sets?)\n",
    "\n",
    "\n",
    "Hints:\n",
    "\n",
    "You can keep your classifiers in a dictionary `class name -> Classifier`\n",
    "Both in fit and predict you need to iterate over all unique classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "class OneVsRestClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_estimator):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.estimators = {}\n",
    "\n",
    "    def fit(self, X, y=None, sample_weight=None):\n",
    "        self.classes = self._extract_classes(y)\n",
    "        print(\"Fitting\")\n",
    "        for cl in self.classes:\n",
    "            est_ = clone(self.base_estimator)\n",
    "            est_.fit(X, self._isin(y, cl))\n",
    "            self.estimators[cl] = est_\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        print(\"Predicting\")\n",
    "        outputs = [[] for _ in range(X.shape[0])]\n",
    "        for cl in self.classes:\n",
    "            true_indices = np.where(self.estimators[cl].predict(X) == 1)[0]\n",
    "            for i in true_indices:\n",
    "                outputs[i].append(cl)\n",
    "        return outputs\n",
    "    \n",
    "    def _extract_classes(self, y_l):\n",
    "        y_l = [ast.literal_eval(x) for x in y]\n",
    "        classes = np.unique([item for sub in y_l for item in sub])\n",
    "        return classes\n",
    "    \n",
    "    def _isin(self, y, cl):\n",
    "        y_l = [ast.literal_eval(x) for x in y]\n",
    "        return np.array([cl in item for item in y_l], dtype=np.int)\n",
    "        \n",
    "\n",
    "#    def _isin(self, ys, cl):\n",
    "#        return np.array([cl in y for y in ys], dtype=np.int)\n",
    "    \n",
    "    \n",
    "def f1(true, pred):\n",
    "    if len(pred) == 0:\n",
    "        return 0\n",
    "    tp = len(set(true).intersection(set(pred)))\n",
    "    precision = tp / len(pred)\n",
    "    recall = tp / len(true)\n",
    "    if (precision + recall) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (2 * precision * recall / (precision + recall))\n",
    "    \n",
    "    \n",
    "def model_definition_words() -> Pipeline:\n",
    "    est = make_pipeline(\n",
    "        CountVectorizer(min_df=5, binary=True, analyzer='word'),\n",
    "        OneVsRestClassifier(base_estimator=RandomForestClassifier(n_estimators=100, min_samples_leaf=10, min_samples_split=20,\n",
    "                                                        n_jobs=-2))\n",
    "    )\n",
    "    return est\n",
    "\n",
    "\n",
    "def validate_model_multiple_outputs():\n",
    "    print('Loading data')\n",
    "    X, y = load_data()\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X[:10000], y[:10000], random_state=1)\n",
    "    est = model_definition_words()\n",
    "    est.fit(X_tr, y_tr)\n",
    "    preds = est.predict(X_te)\n",
    "    mean_f1 = np.array([f1(true, pred) for true, pred in zip(y_te, preds)]).mean()\n",
    "    print(\"Multiple Labels F1\", mean_f1)\n",
    "    \n",
    "#validate_model_multiple_outputs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting\n",
      "Predicting\n"
     ]
    }
   ],
   "source": [
    "X_tr, X_te, y_tr, y_te = train_test_split(X[:10000], y[:10000], random_state=1)\n",
    "est = model_definition_words()\n",
    "est.fit(X_tr, y_tr)\n",
    "preds = est.predict(X_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def isin(y_l, cl):\n",
    "    #y_l = [ast.literal_eval(x) for x in y]\n",
    "    return np.array([cl in item for item in y_l], dtype=np.int)\n",
    "\n",
    "\n",
    "est = make_pipeline(\n",
    "    CountVectorizer(min_df=5, binary=True, analyzer='word'),\n",
    "    RandomForestClassifier())\n",
    "\n",
    "\n",
    "y_l = [ast.literal_eval(x) for x in y_tr]\n",
    "est.fit(X_tr, isin(y_l, 'Consulting'))\n",
    "est.predict(X_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['3D Printing', '3D Technology', 'Accounting', 'Ad Exchange',\n",
       "       'Ad Network', 'Ad Targeting', 'Advanced Materials',\n",
       "       'Adventure Travel', 'Advertising', 'Advertising Exchanges',\n",
       "       'Advertising Platforms', 'Advice', 'Aerospace',\n",
       "       'Affiliate Marketing', 'AgTech', 'Agriculture',\n",
       "       'Air Transportation', 'Alternative Medicine', 'Alumni',\n",
       "       'Analytics', 'Android', 'Angel Investment', 'Animal Feed',\n",
       "       'Animation', 'App Discovery', 'App Marketing',\n",
       "       'Application Performance Management', 'Application Platforms',\n",
       "       'Apps', 'Architecture', 'Art', 'Artificial Intelligence',\n",
       "       'Asset Management', 'Auctions', 'Audio', 'Augmented Reality',\n",
       "       'Auto Insurance', 'Automotive', 'Autonomous Vehicles', 'B2B',\n",
       "       'B2C', 'Baby', 'Banking', 'Battery', 'Beauty', 'Big Data',\n",
       "       'Big Data Analytics', 'Bike', 'Billing', 'Biometrics', 'Biopharma',\n",
       "       'Biotechnology', 'Bitcoin', 'Blogging Platforms', 'Boating',\n",
       "       'Brand Marketing', 'Brewing', 'Broadcasting', 'Browser Extensions',\n",
       "       'Building Material', 'Business Development',\n",
       "       'Business Information Systems', 'Business Intelligence',\n",
       "       'Business Services', 'Business Travel', 'CAD', 'CRM',\n",
       "       'Call Center', 'Car Sharing', 'Career Planning', 'Casino',\n",
       "       'Casual Games', 'Celebrity', 'Charity', 'Charter Schools',\n",
       "       'Chemical', 'Chemical Engineering', 'Child Care', 'Children',\n",
       "       'Civil Engineering', 'Classifieds', 'Clean Energy', 'CleanTech',\n",
       "       'Clinical Trials', 'Cloud Computing', 'Cloud Data Services',\n",
       "       'Cloud Infrastructure', 'Cloud Management', 'Cloud Security',\n",
       "       'Cloud Storage', 'Coffee', 'Collaboration',\n",
       "       'Collaborative Consumption', 'Collectibles', 'College Recruiting',\n",
       "       'Comics', 'Commercial', 'Commercial Lending',\n",
       "       'Commercial Real Estate', 'Communication Hardware',\n",
       "       'Communications Infrastructure', 'Communities', 'Compliance',\n",
       "       'Computer', 'Computer Vision', 'Concerts', 'Confectionery',\n",
       "       'Construction', 'Consulting', 'Consumer', 'Consumer Electronics',\n",
       "       'Consumer Goods', 'Consumer Lending', 'Consumer Reviews',\n",
       "       'Consumer Software', 'Contact Management', 'Content',\n",
       "       'Content Creators', 'Content Delivery Network',\n",
       "       'Content Discovery', 'Content Marketing', 'Content Syndication',\n",
       "       'Cooking', 'Corporate Training', 'Cosmetic Surgery', 'Cosmetics',\n",
       "       'Coupons', 'Coworking', 'Craft Beer', 'Creative Agency', 'Credit',\n",
       "       'Credit Cards', 'Crowdfunding', 'Crowdsourcing', 'Cryptocurrency',\n",
       "       'Curated Web', 'Customer Service', 'Cyber Security', 'Cycling',\n",
       "       'DIY', 'DSP', 'Data Center', 'Data Center Automation',\n",
       "       'Data Integration', 'Data Mining', 'Data Storage',\n",
       "       'Data Visualization', 'Database', 'Databases', 'Dating',\n",
       "       'Debit Cards', 'Debt Collections', 'Delivery', 'Delivery Service',\n",
       "       'Dental', 'Design', 'Developer APIs', 'Developer Platform',\n",
       "       'Developer Tools', 'Diabetes', 'Dietary Supplements',\n",
       "       'Digital Entertainment', 'Digital Marketing', 'Digital Media',\n",
       "       'Digital Signage', 'Direct Marketing', 'Direct Sales',\n",
       "       'Distillery', 'Diving', 'Document Management',\n",
       "       'Document Preparation', 'Domain Registrar', 'Drone Management',\n",
       "       'Drones', 'E-Commerce', 'E-Commerce Platforms', 'E-Learning',\n",
       "       'EBooks', 'EDA', 'ERP', 'EdTech', 'Ediscovery', 'Education',\n",
       "       'Elderly', 'Electric Vehicle', 'Electrical Distribution',\n",
       "       'Electronics', 'Email', 'Email Marketing',\n",
       "       'Embedded Hardware and Software', 'Embedded Software',\n",
       "       'Embedded Systems', 'Emerging Markets', 'Employee Benefits',\n",
       "       'Employment', 'Energy', 'Energy Efficiency', 'Energy Management',\n",
       "       'Energy Storage', 'Enterprise', 'Enterprise Applications',\n",
       "       'Enterprise Software', 'Environmental Consulting',\n",
       "       'Environmental Engineering', 'Event Management', 'Event Promotion',\n",
       "       'Events', 'Eyewear', 'FMCG', 'Facebook', 'Family',\n",
       "       'Fantasy Sports', 'Farming', 'Fashion', 'Fertility',\n",
       "       'File Sharing', 'Film', 'Film Distribution', 'Film Production',\n",
       "       'FinTech', 'Finance', 'Financial Exchanges', 'Financial Services',\n",
       "       'Fitness', 'Fleet Management', 'Food Delivery', 'Food Processing',\n",
       "       'Food and Beverage', 'Franchise', 'Fraud Detection', 'Freemium',\n",
       "       'Fuel', 'Funerals', 'Furniture', 'GPS', 'Gambling', 'Gamification',\n",
       "       'Gaming', 'Genetics', 'Geospatial', 'Gift', 'Gift Card',\n",
       "       'Gift Exchange', 'GovTech', 'Government', 'Graphic Design',\n",
       "       'Green Building', 'GreenTech', 'Grocery', 'Group Buying', 'Guides',\n",
       "       'Handmade', 'Hardware', 'Health Care', 'Health Diagnostics',\n",
       "       'Health Insurance', 'Health and Wellness', 'Hedge Funds',\n",
       "       'Higher Education', 'Home & Garden', 'Home Automation',\n",
       "       'Home Decor', 'Home Health Care', 'Home Improvement',\n",
       "       'Home Renovation', 'Home Services', 'Home and Garden',\n",
       "       'Homeland Security', 'Hospital', 'Hospitality', 'Hotel',\n",
       "       'Human Computer Interaction', 'Human Resources', 'Humanitarian',\n",
       "       'ICT', 'ISP', 'IT Infrastructure', 'IT Management', 'IaaS',\n",
       "       'Identity', 'Identity Management', 'Image Recognition',\n",
       "       'Impact Investing', 'In-Flight Entertainment', 'Incubators',\n",
       "       'Indoor Positioning', 'Industrial', 'Industrial Automation',\n",
       "       'Industrial Engineering', 'Information Services',\n",
       "       'Information Technology', 'Infrastructure',\n",
       "       'Innovation Management', 'Insurance', 'Intellectual Property',\n",
       "       'Intelligent Systems', 'Interior Design', 'Internet',\n",
       "       'Internet Marketing', 'Internet of Things',\n",
       "       'Investment Management', 'Jewelry', 'Journalism',\n",
       "       'Knowledge Management', 'Landscaping', 'Language Learning',\n",
       "       'Laser', 'Law Enforcement', 'Lead Generation', 'Lead Management',\n",
       "       'Legal', 'Leisure', 'Lending', 'Life Science', 'Lifestyle',\n",
       "       'Lighting', 'Limousine Service', 'Lingerie', 'Linux', 'Livestock',\n",
       "       'Local', 'Local Advertising', 'Local Business', 'Local Shopping',\n",
       "       'Location Based Services', 'Logistics', 'Loyalty Programs',\n",
       "       'MMO Games', 'Machine Learning', 'Machinery Manufacturing',\n",
       "       'Management Consulting', 'Management Information Systems',\n",
       "       'Manufacturing', 'Mapping Services', 'Market Research',\n",
       "       'Marketing', 'Marketing Automation', 'Marketplace', 'Marketplaces',\n",
       "       'Mechanical Engineering', 'Media', 'Media and Entertainment',\n",
       "       'Medical', 'Medical Device', 'Meeting Software', 'Messaging',\n",
       "       'Millennials', 'Mineral', 'Mining', 'Mining Technology', 'Mobile',\n",
       "       'Mobile Advertising', 'Mobile Apps', 'Mobile Commerce',\n",
       "       'Mobile Devices', 'Mobile Payments', 'Mobile Software Tools',\n",
       "       'Mothers', 'Motion Capture', 'Multi-level Marketing',\n",
       "       'Museums and Historical Sites', 'Music', 'Music Education',\n",
       "       'Music Streaming', 'Music Venues', 'Musical Instruments', 'NFC',\n",
       "       'Nanotechnology', 'National Security',\n",
       "       'Natural Language Processing', 'Natural Resources', 'Navigation',\n",
       "       'Network Hardware', 'Network Security', 'Neuroscience', 'News',\n",
       "       'Nightlife', 'Non Profit', 'Nuclear',\n",
       "       'Nursing and Residential Care', 'Nutraceutical', 'Nutrition',\n",
       "       'Office Administration', 'Oil and Gas', 'Online Auctions',\n",
       "       'Online Forums', 'Online Games', 'Online Portals', 'Online Travel',\n",
       "       'Open Source', 'Optical Communication', 'Organic', 'Organic Food',\n",
       "       'Outdoor Advertising', 'Outdoors', 'Outsourcing', 'PC Games',\n",
       "       'PaaS', 'Packaging Services', 'Parenting', 'Parking', 'Payments',\n",
       "       'Peer to Peer', 'Performing Arts', 'Personal Development',\n",
       "       'Personal Finance', 'Personal Health', 'Personalization', 'Pet',\n",
       "       'Pharmaceutical', 'Photo Editing', 'Photo Sharing', 'Photography',\n",
       "       'Physical Security', 'Plastics and Rubber Manufacturing',\n",
       "       'Podcast', 'Point of Sale', 'Politics', 'Precious Metals',\n",
       "       'Predictive Analytics', 'Price Comparison', 'Primary Education',\n",
       "       'Printing', 'Privacy', 'Private Social Networking', 'Procurement',\n",
       "       'Product Design', 'Product Management', 'Product Search',\n",
       "       'Productivity Software', 'Productivity Tools',\n",
       "       'Professional Networking', 'Professional Services',\n",
       "       'Project Management', 'Property Development', 'Property Insurance',\n",
       "       'Property Management', 'Psychology', 'Public Relations',\n",
       "       'Public Safety', 'Public Transportation', 'Publishing', 'Q&A',\n",
       "       'QR Codes', 'Quality Assurance', 'Quantified Self', 'RFID',\n",
       "       'Racing', 'Railroad', 'Reading Apps', 'Real Estate',\n",
       "       'Real Estate Investment', 'Real Time', 'Recipes', 'Recreation',\n",
       "       'Recreational Vehicles', 'Recruiting', 'Recycling', 'Religion',\n",
       "       'Renewable Energy', 'Rental', 'Reputation', 'Reservations',\n",
       "       'Residential', 'Resorts', 'Restaurants', 'Retail',\n",
       "       'Retail Technology', 'Retirement', 'Ride Sharing',\n",
       "       'Risk Management', 'Robotics', 'SEM', 'SEO', 'SMS', 'SNS', 'SaaS',\n",
       "       'Sales', 'Sales Automation', 'Satellite Communication',\n",
       "       'Scheduling', 'Search', 'Search Engine', 'Search Marketing',\n",
       "       'Security', 'Self-Storage', 'Semantic Search', 'Semantic Web',\n",
       "       'Semiconductor', 'Sensor', 'Service Industry', 'Services',\n",
       "       'Sharing Economy', 'Shipping', 'Shipping Broker', 'Shopping',\n",
       "       'Skill Assessment', 'Small and Medium Businesses',\n",
       "       'Smart Building', 'Social', 'Social Bookmarking', 'Social CRM',\n",
       "       'Social Entrepreneurship', 'Social Innovation', 'Social Media',\n",
       "       'Social Media Advertising', 'Social Media Management',\n",
       "       'Social Media Marketing', 'Social Network', 'Social Network Media',\n",
       "       'Social News', 'Social Recruiting', 'Software',\n",
       "       'Software Engineering', 'Solar', 'Space Travel',\n",
       "       'Speech Recognition', 'Sporting Goods', 'Sports',\n",
       "       'Staffing Agency', 'Stock Exchanges', 'Subscription Service',\n",
       "       'Supply Chain Management', 'Sustainability', 'TV',\n",
       "       'Task Management', 'Taxi Service', 'Tea', 'Technical Support',\n",
       "       'Technology', 'Teenagers', 'Telecommunications',\n",
       "       'Test and Measurement', 'Text Analytics', 'Textiles', 'Theatre',\n",
       "       'Therapeutics', 'Ticketing', 'Tobacco', 'Tour Operator', 'Tourism',\n",
       "       'Toys', 'Trading Platform', 'Training', 'Transaction Processing',\n",
       "       'Translation', 'Transportation', 'Travel', 'Travel Accommodations',\n",
       "       'Travel Agency', 'Tutoring', 'Twitter', 'UX Design',\n",
       "       'Underserved Children', 'Unified Communications', 'Universities',\n",
       "       'Usability Testing', 'Vacation Rental', 'Vending and Concessions',\n",
       "       'Venture Capital', 'Veterinary', 'Video', 'Video Advertising',\n",
       "       'Video Chat', 'Video Conferencing', 'Video Editing', 'Video Games',\n",
       "       'Video Streaming', 'Video on Demand', 'Virtual Currency',\n",
       "       'Virtual Goods', 'Virtual Reality', 'Virtualization',\n",
       "       'Visual Search', 'VoIP', 'Warehousing', 'Waste Management',\n",
       "       'Water', 'Water Purification', 'Wealth Management', 'Wearables',\n",
       "       'Web Apps', 'Web Browsers', 'Web Design', 'Web Development',\n",
       "       'Web Hosting', 'Wedding', 'Wellness', 'Wholesale', 'Wind Energy',\n",
       "       'Wine And Spirits', 'Wireless', \"Women's\", 'eSports', 'iOS',\n",
       "       'mHealth', 'macOS'], dtype='<U34')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_l = [ast.literal_eval(x) for x in y_tr]\n",
    "classes = np.unique([item for sub in y_l for item in sub])\n",
    "for cl in classes:\n",
    "    est_ = clone(RandomForestClassifier())\n",
    "    est_.fit(X_tr, isin(y, cl))\n",
    "#    self.estimators[cl] = est_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Consulting' in m[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " False,\n",
       " True,\n",
       " False,\n",
       " False,\n",
       " ...]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "['Consulting' in item for item in m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     website  \\\n",
      "0                           http://iFans.com   \n",
      "1                    http://www.braingig.com   \n",
      "2                 https://www.twinelabs.com/   \n",
      "3                   http://www.SumaGreen.com   \n",
      "4  http://worldstartupreport.strikingly.com/   \n",
      "\n",
      "                                         categories  \\\n",
      "0                                          ['News']   \n",
      "1                         ['Non Profit', 'Finance']   \n",
      "2                                                []   \n",
      "3                                 ['Biotechnology']   \n",
      "4  ['Market Research', 'CleanTech', 'Clean Energy']   \n",
      "\n",
      "                                   short_description  \n",
      "0  iFans is a community-based forum and portal th...  \n",
      "1              Connecting grant funders and seekers.  \n",
      "2  Twine is a powerful platform for internal mobi...  \n",
      "3  SumaGreen is an agro firm committed to enablin...  \n",
      "4  World Startup Report is a social mission to do...  \n",
      "Fitting\n",
      "Predicting\n"
     ]
    }
   ],
   "source": [
    "X, y = load_data()\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X[:10000], y[:10000], random_state=1)\n",
    "est = model_definition_words()\n",
    "est.fit(X_tr, y_tr)\n",
    "preds = est.predict(X_te)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False, ...,  True,  True,  True])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "np.array(['a' in x for x in y_te])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.38095238, 0.625     , 0.66666667, ..., 0.13888889, 0.08695652,\n",
       "       0.43636364])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([cl in y for y in ys], dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([\"['SaaS', 'Computer', 'Software']\", \"['Finance']\", '[]', ...,\n",
       "       \"['Fitness', 'Health Care', 'Lifestyle', 'Gamification', 'Software']\",\n",
       "       \"['Electrical Distribution', 'Electronics', 'Test and Measurement']\",\n",
       "       \"['E-Commerce', 'Electronics', 'Industrial']\"], dtype=object)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f1(true, pred):\n",
    "    if len(pred) == 0:\n",
    "        return 0\n",
    "    tp = len(set(true).intersection(set(pred)))\n",
    "    precision = tp / len(pred)\n",
    "    recall = tp / len(true)\n",
    "    if (precision + recall) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (2 * precision * recall / (precision + recall))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['SaaS', 'Computer', 'Software']\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ',\n",
       " \"'\",\n",
       " ',',\n",
       " 'C',\n",
       " 'S',\n",
       " '[',\n",
       " ']',\n",
       " 'a',\n",
       " 'e',\n",
       " 'f',\n",
       " 'm',\n",
       " 'o',\n",
       " 'p',\n",
       " 'r',\n",
       " 't',\n",
       " 'u',\n",
       " 'w'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(y_te[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.groupby('categories').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a>Show answers</a>\n",
    "\n",
    "<div class='spoiler'>\n",
    "class OneVsRestClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, base_estimator):\n",
    "        self.base_estimator = base_estimator\n",
    "        self.estimators = {}\n",
    "\n",
    "    def fit(self, X, y=None, sample_weight=None):\n",
    "        self.classes = list(set(chain(*y)))\n",
    "        print(\"Fitting\")\n",
    "        for cl in tqdm(self.classes):\n",
    "            est_ = clone(self.base_estimator)\n",
    "            est_.fit(X, self._isin(y, cl))\n",
    "            self.estimators[cl] = est_\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        print(\"Predicting\")\n",
    "        outputs = [[] for _ in range(X.shape[0])]\n",
    "        for cl in tqdm(self.classes):\n",
    "            true_indices = np.where(self.estimators[cl].predict(X) == 1)[0]\n",
    "            for i in true_indices:\n",
    "                outputs[i].append(cl)\n",
    "        return outputs\n",
    "\n",
    "    def _isin(self, ys, cl):\n",
    "        return np.array([cl in y for y in ys], dtype=np.int)\n",
    "    \n",
    "    \n",
    "def f1(true, pred):\n",
    "    if len(pred) == 0:\n",
    "        return 0\n",
    "    tp = len(set(true).intersection(set(pred)))\n",
    "    precision = tp / len(pred)\n",
    "    recall = tp / len(true)\n",
    "    if (precision + recall) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (2 * precision * recall / (precision + recall))\n",
    "    \n",
    "    \n",
    "def model_definition_words() -> Pipeline:\n",
    "    est = make_pipeline(\n",
    "        CountVectorizer(min_df=5, binary=True, analyzer='word'),\n",
    "        OneVsRestClassifier(base_estimator=RandomForestClassifier(n_estimators=100, min_samples_leaf=10, min_samples_split=20,\n",
    "                                                        n_jobs=-2))\n",
    "    )\n",
    "    return est\n",
    "\n",
    "\n",
    "def validate_model_multiple_outputs():\n",
    "    print('Loading data')\n",
    "    X, y = load_data()\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(X[:10000], y[:10000], random_state=1)\n",
    "    est = model_definition_words()\n",
    "    est.fit(X_tr, y_tr)\n",
    "    preds = est.predict(X_te)\n",
    "    mean_f1 = np.array([f1(true, pred) for true, pred in zip(y_te, preds)]).mean()\n",
    "    print(\"Multiple Labels F1\", mean_f1)\n",
    "    \n",
    "validate_model_multiple_outputs()\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
