{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'> HERE! Insert a recap</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumption:\n",
    "- We will be using scikit-learn interface to pipelines\n",
    "- We will work with Pandas Dataframes for transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformers** are python classes used in data manipulation to select features, normalize, reduce dimension,... permorf transformations on data.\n",
    "A Transformer implements the method ``transform`` that applies the transformation. Examples:\n",
    "- a transformer might take a Dataframe and add a column to it\n",
    "- a tranformer might take an array as input, calculate the mean and normalize it\n",
    "\n",
    "**Estimators** are python classes that learns something from the data by \"fitting\" or \"training\" on data. Estimators implement the method ``fit``, which accepts an input (DataFrame, Array, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot Encoder (Transformer)\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html\n",
    "    \n",
    "Logistic Regression (Estimator)\n",
    "    https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformer** are said to be:\n",
    "- **statefull** if they learn something from the data using the ``fit`` method\n",
    "- **stateless** if they do not need to learn (the ``fit`` method does not do anything)\n",
    "\n",
    "Example of a stateless Transformer in scikit-learn: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.Normalizer.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Transformer and Estimators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In scikit-learn it is possible to write your own transformers and estimators to perform transformations on data or to use a custom model for making predictions.\n",
    "In scikit-learn custom transformers are written as classes that inherit attributes and methods from two special scikit-learn classes: ``BaseEstimator`` and ``TransformerMixin``\n",
    "\n",
    "```python\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CustomTransformer(BaseEstimator, TransformerMixin):\n",
    "    ....\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```BaseEstimator``` https://github.com/scikit-learn/scikit-learn/blob/a24c8b46/sklearn/base.py#L176\n",
    "This is a python class that represents the base from all estimators. An estimator can inherit methods from the BaseEstimator like ```get_param```\n",
    "\n",
    "```TransformerMixin``` https://github.com/scikit-learn/scikit-learn/blob/a24c8b46/sklearn/base.py#L490\n",
    "A Mixin is a class that contains method used by other classes without having to be parent class of those other classes (ex. the method ``fit_transform`` that concatenates fit+transform methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you give an example of a scikit-learn estimator that inherits from the BaseEstimator?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of a Transformer that does not do anything\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class LazyTransformer(BaseEstimator, TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, x, y = None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, x):\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise\n",
    "--------------\n",
    "\n",
    "1. Write a transformer that adds some number to the input, the number that is added should be passed in `__init__`\n",
    "2. Write a transformer that normalizes the input:\n",
    "   - in the fit method you must save the column means\n",
    "3. Combine these 2 transformers into a pipeline:\n",
    "   - hint: write a class that accepts list of transformers as argument"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline and make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word \"Pipeline\" can refer to different things in software engeneering. In our context we use this word to refer to scikit-learn pipelines:\n",
    "Theses are **sequences** of transformers that end with a final estimator. Intermediate steps of the pipelines must have fit and transform methods, while the very last step must have just a fit method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different ways to create a Pipeline in scikit-learn: \n",
    "\n",
    "1.```Pipeline```\n",
    "\n",
    "2.```make_pipeline```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Pipeline** is a class in scikit-learn:```class sklearn.pipeline.Pipeline(steps, memory=None)```\n",
    "\n",
    "```python \n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "Pipeline(steps = [('transformer_one', Transformer1(...)),\n",
    "                 ('transformer_two', Transformer2(...)),\n",
    "                 ....\n",
    "                 ('final_estimator', Model(...))])\n",
    "````\n",
    "Example 1:\n",
    "```python\n",
    "Pipeline([('vec', CountVectorizer()), ('clf', LogisticRegression())])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **make_pipeline** is a python function that represents a shorthard for ```Pipeline``` constructor\n",
    "\n",
    "```python\n",
    "from scikit.pipeline import make_pipeline\n",
    "\n",
    "make_pipeline(Transformer1(...),Transformer2(...), ... , Model())\n",
    "```\n",
    "Example 2:\n",
    "```python\n",
    "make_pipeline(CountVectorizer(), LogisticRegression()) \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only difference between ```Pipeline``` and ```make_pipeline``` is that with Pipeline you need to specify the names of each Estimator. This can be usefull if you need to use model selection utilities (like ```GridSearch```):\n",
    "\n",
    "Example 1:\n",
    "\n",
    "```python\n",
    "pipe = Pipeline([('vec', CountVectorizer()), ('clf', LogisticRegression())])\n",
    "param_grid = [{'clf__C': [1, 10, 100, 1000]}]\n",
    "gs = GridSearchCV(pipe, param_grid)\n",
    "gs.fit(X,y)\n",
    "```\n",
    "\n",
    "Example 2:\n",
    "\n",
    "```python\n",
    "pipe = make_pipeline(CountVectorizer(), LogisticRegression())\n",
    "param_grid = [{'logisticregression__C': [1, 10, 100, 1000]}]\n",
    "gs = GridSearchCV(pipe, param_grid)\n",
    "gs.fit(X,y)\n",
    "```\n",
    "\n",
    "As a consequence of this, using Pipeline we could for example replace the final estimator (from LosticRegression to RandomForest) and the name of the estimator would stay the same. On the other hand, with make_pipeline the names of the steps are autogenerated.\n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By calling ```fit``` on the pipeline, all the transformers in the pipeline are applied with fit and transform methods\n",
    "one after the other: the transformed data is passed to the next transformer as input and the fit method of the last estimator is called. The method ```fit_predict``` fit the pipeline and generates the predictions from the last estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FeatureUnion and make_union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In certain situations you want to apply a list of transformers in parallel instead of one after the other.\n",
    "\n",
    "Example: you have text data and you want to extract words frequencies using ```CountVectorizer``` and you also want to use the length of the text as feature. In this case a pipeline of estimators is not suitable since you need to do the operation on the same data and you cannot apply a transformer after the other. \n",
    "\n",
    "```FeatureUnion``` and its corresponding shorthand version ```make_union``` creates a union of transformers and concatenate their results.\n",
    "\n",
    "Example:\n",
    "```python\n",
    "from scikit.pipeline import FeatureUnion\n",
    "featunion = FeatureUnion([('count_vect', CountVectorizer(...)),('length', CustomTransformer(...))])\n",
    "# you can then combine the FeatureUnion into a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('feats', featunion),\n",
    "    ('clf', Classifier())  # classifier\n",
    "])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
